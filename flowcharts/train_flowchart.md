```mermaid
graph TD
    START([é–‹å§‹]) -->|å‘½ä»¤è¡Œåƒæ•¸| PARSE["main()<br/>è§£æåƒæ•¸:<br/>--config, --init-model"]
    PARSE --> INIT["TrainPipeline.__init__()<br/>åˆå§‹åŒ–è¨“ç·´ç®¡é“"]
    
    INIT --> LOAD_CFG["load_config()<br/>åŠ è¼‰ config.json<br/>(board, training, network)"]
    LOAD_CFG --> SETUP_BOARD["è¨­å®šæ£‹ç›¤<br/>Board(width, height, n_in_row)<br/>Game(board)"]
    SETUP_BOARD --> SETUP_DYNAMIC["åˆå§‹åŒ–å‹•æ…‹åƒæ•¸<br/>DynamicTrainingParams<br/>â”œâ”€ temp (temperature)<br/>â”œâ”€ n_playout (æ¨¡æ“¬æ¬¡æ•¸)<br/>â””â”€ c_puct (æ¢ç´¢ä¿‚æ•¸)"]
    SETUP_DYNAMIC --> SETUP_PARAMS["è¨­å®šè¨“ç·´åƒæ•¸<br/>â”œâ”€ learn_rate, lr_multiplier<br/>â”œâ”€ buffer_size, batch_size<br/>â”œâ”€ epochs, kl_targ<br/>â”œâ”€ play_batch_size<br/>â””â”€ check_freq"]
    SETUP_PARAMS --> CHECK_GPU{"GPU<br/>å¯ç”¨?"}
    
    CHECK_GPU -->|å¦| ERROR1["éŒ¯èª¤: CUDA ä¸å¯ç”¨<br/>RuntimeError"]
    ERROR1 --> END1([ä¸­æ–·])
    
    CHECK_GPU -->|æ˜¯| LOAD_NET["PolicyValueNet<br/>â”œâ”€ ResNet æ¶æ§‹<br/>â”œâ”€ num_channels (128)<br/>â”œâ”€ num_res_blocks (4-6)<br/>â””â”€ åŠ è¼‰ init_model (å¯é¸)"]
    LOAD_NET --> INIT_MCTS["MCTSPlayer(is_selfplay=1)<br/>â”œâ”€ policy_value_fn<br/>â”œâ”€ c_puct (åˆå§‹å€¼)<br/>â””â”€ n_playout (åˆå§‹å€¼)"]
    INIT_MCTS --> RUN["TrainPipeline.run()<br/>é–‹å§‹è¨“ç·´è¿´åœˆ"]
    
    RUN --> BATCH_LOOP["æ‰¹æ¬¡è¿´åœˆ<br/>for i in range(game_batch_num)"]
    BATCH_LOOP --> UPDATE_DYN["æ›´æ–°å‹•æ…‹åƒæ•¸<br/>get_all_params(i)<br/>â”œâ”€ æ›´æ–° c_puct<br/>â”œâ”€ æ›´æ–° n_playout<br/>â””â”€ æ›´æ–° temperature"]
    UPDATE_DYN --> UPDATE_MCTS["æ›´æ–° MCTS ç©å®¶<br/>MCTSPlayer(<br/>  policy_value_fn,<br/>  c_puct=æ–°å€¼,<br/>  n_playout=æ–°å€¼,<br/>  is_selfplay=1<br/>)"]
    UPDATE_MCTS --> COLLECT["collect_selfplay_data()<br/>play_batch_size å ´éŠæˆ²"]
    
    COLLECT --> SELF_PLAY["Game.start_self_play()<br/>å–®å ´è‡ªæˆ‘å°å¼ˆ"]
    SELF_PLAY --> INIT_BOARD["Board.init_board()<br/>åˆå§‹åŒ–ç©ºæ£‹ç›¤"]
    INIT_BOARD --> MOVE_LOOP["è‘—æ³•è¿´åœˆ<br/>while not game_end"]
    
    MOVE_LOOP --> GET_ACTION["MCTSPlayer.get_action()<br/>â”œâ”€ temp=temperature<br/>â””â”€ return_prob=1"]
    GET_ACTION --> MCTS_SEARCH["MCTS.get_move_probs()<br/>åŸ·è¡Œ n_playout æ¬¡æ¨¡æ“¬"]
    MCTS_SEARCH --> PLAYOUT_LOOP["æ¨¡æ“¬è¿´åœˆ<br/>for n in range(n_playout)"]
    
    PLAYOUT_LOOP --> SINGLE_PLAYOUT["å–®æ¬¡æ¨¡æ“¬ _playout()<br/>â”œâ”€ å¾æ ¹ç¯€é»é–‹å§‹<br/>â”œâ”€ é¸æ“‡: node.select(c_puct)<br/>â”‚  â””â”€ æœ€å¤§åŒ– Q + u<br/>â”œâ”€ å±•é–‹: node.expand()<br/>â”‚  â””â”€ policy_value_fn(state)<br/>â”‚     â””â”€ ResNet å‰å‘å‚³æ’­<br/>â””â”€ å›å‚³: update_recursive()"]
    SINGLE_PLAYOUT --> PLAYOUT_END{"å®Œæˆ<br/>n_playout<br/>æ¬¡?"}
    PLAYOUT_END -->|å¦| PLAYOUT_LOOP
    PLAYOUT_END -->|æ˜¯| CALC_PROBS["è¨ˆç®—è¨ªå•æ¦‚ç‡<br/>act_probs = softmax(<br/>  1/temp Ã— log(visits)<br/>)"]
    
    CALC_PROBS --> ADD_NOISE{"is_selfplay<br/>== 1?"}
    ADD_NOISE -->|æ˜¯| DIRICHLET["ğŸ² æ·»åŠ  Dirichlet é›œè¨Š<br/>move = choice(acts,<br/>  p = 0.8Ã—probs +<br/>      0.2Ã—Dir(Î±=0.15)<br/>)<br/>â””â”€ å¢åŠ æ¢ç´¢å¤šæ¨£æ€§"]
    ADD_NOISE -->|å¦| NO_NOISE["é¸æ“‡æœ€å¤§æ¦‚ç‡è‘—æ³•<br/>move = choice(acts, p=probs)"]
    
    DIRICHLET --> RECORD["è¨˜éŒ„è¨“ç·´æ•¸æ“š<br/>â”œâ”€ state â† board.current_state()<br/>â”œâ”€ mcts_probs â† move_probs<br/>â””â”€ current_player"]
    NO_NOISE --> RECORD
    RECORD --> DO_MOVE["Board.do_move(move)<br/>â”œâ”€ states[move] = player<br/>â”œâ”€ availables.remove(move)<br/>â””â”€ åˆ‡æ›ç©å®¶"]
    DO_MOVE --> CHECK_END{"game_end()?"}
    
    CHECK_END -->|å¦| MOVE_LOOP
    CHECK_END -->|æ˜¯| ASSIGN_REWARD["åˆ†é…çå‹µå€¼<br/>winners_z:<br/>â”œâ”€ å‹è€… +1.0<br/>â”œâ”€ æ•—è€… -1.0<br/>â””â”€ å¹³æ‰‹  0.0"]
    ASSIGN_REWARD --> RETURN_DATA["è¿”å› (winner, play_data)<br/>play_data = zip(<br/>  states,<br/>  mcts_probs,<br/>  winners_z<br/>)"]
    
    RETURN_DATA --> DATA_AUG["get_equi_data()<br/>è³‡æ–™å¢å¼· (8å€)"]
    DATA_AUG --> AUG_DETAIL["å°æ¯å€‹ (state, prob, z):<br/>â”œâ”€ æ—‹è½‰ 4 æ¬¡ (0Â°,90Â°,180Â°,270Â°)<br/>â”‚  â””â”€ æ¯æ¬¡æ—‹è½‰ Ã— ç¿»è½‰ 2 æ¬¡<br/>â””â”€ ç”Ÿæˆ 8 å€‹ç­‰åƒ¹æ¨£æœ¬"]
    AUG_DETAIL --> EXTEND_BUFFER["data_buffer.extend()<br/>æ·»åŠ åˆ°ç¶“é©—å›æ”¾æ± <br/>(maxlen=buffer_size)"]
    
    EXTEND_BUFFER --> PRINT_INFO["æ‰“å°:<br/>batch i, episode_len<br/>n_playout, c_puct, temp"]
    PRINT_INFO --> CHECK_BUFFER{"len(data_buffer)<br/>> batch_size?"}
    
    CHECK_BUFFER -->|å¦| SKIP_TRAIN["è·³éè¨“ç·´<br/>ç¹¼çºŒæ”¶é›†æ•¸æ“š"]
    CHECK_BUFFER -->|æ˜¯| POLICY_UPD["policy_update()<br/>ç¥ç¶“ç¶²è·¯è¨“ç·´"]
    
    POLICY_UPD --> SAMPLE["random.sample()<br/>æ¡æ¨£ batch_size å€‹æ¨£æœ¬<br/>â”œâ”€ state_batch<br/>â”œâ”€ mcts_probs_batch<br/>â””â”€ winner_batch"]
    SAMPLE --> GET_OLD["è¨ˆç®—èˆŠç­–ç•¥<br/>old_probs, old_v =<br/>  policy_value_net<br/>    .policy_value(state_batch)"]
    GET_OLD --> EPOCH_LOOP["è¨“ç·´è¿´åœˆ<br/>for i in range(epochs)"]
    
    EPOCH_LOOP --> TRAIN_STEP["train_step()<br/>â”œâ”€ zero_grad()<br/>â”œâ”€ set_learning_rate(<br/>â”‚    lr Ã— lr_multiplier)<br/>â”œâ”€ å‰å‘å‚³æ’­:<br/>â”‚  log_act_probs, value<br/>â”œâ”€ è¨ˆç®—æå¤±:<br/>â”‚  value_loss = MSE(v, z)<br/>â”‚  policy_loss = -Î£ Ï€Â·log(p)<br/>â”‚  loss = value_loss<br/>â”‚         + policy_loss<br/>â”œâ”€ backward()<br/>â””â”€ optimizer.step()"]
    TRAIN_STEP --> GET_NEW["è¨ˆç®—æ–°ç­–ç•¥<br/>new_probs, new_v"]
    GET_NEW --> CALC_KL["è¨ˆç®— KL æ•£åº¦<br/>KL = Î£ old_probs Ã—<br/>  log(old_probs / new_probs)"]
    CALC_KL --> CHECK_KL{"KL ><br/>4Ã—kl_targ?"}
    
    CHECK_KL -->|æ˜¯| EARLY_STOP["æå‰åœæ­¢<br/>break<br/>(é¿å…ç­–ç•¥è®ŠåŒ–éå¤§)"]
    CHECK_KL -->|å¦| CONTINUE_EPOCH["ç¹¼çºŒè¨“ç·´"]
    EARLY_STOP --> EPOCH_END
    CONTINUE_EPOCH --> EPOCH_DONE{"å®Œæˆ<br/>epochs?"}
    EPOCH_DONE -->|å¦| EPOCH_LOOP
    EPOCH_DONE -->|æ˜¯| EPOCH_END["Epochs å®Œæˆ"]
    
    EPOCH_END --> ADJUST_LR["è‡ªé©æ‡‰å­¸ç¿’ç‡èª¿æ•´"]
    ADJUST_LR --> CHECK_KL_HI{"KL > 2Ã—kl_targ<br/>AND<br/>lr_mult > 0.1?"}
    CHECK_KL_HI -->|æ˜¯| LR_DOWN["lr_multiplier /= 1.5<br/>(é™ä½å­¸ç¿’ç‡)"]
    CHECK_KL_HI -->|å¦| CHECK_KL_LO{"KL < kl_targ/2<br/>AND<br/>lr_mult < 10?"}
    LR_DOWN --> CHECK_KL_LO
    CHECK_KL_LO -->|æ˜¯| LR_UP["lr_multiplier Ã—= 1.5<br/>(æé«˜å­¸ç¿’ç‡)"]
    CHECK_KL_LO -->|å¦| CALC_EXPL
    LR_UP --> CALC_EXPL["è¨ˆç®—å¯è§£é‡‹æ–¹å·®<br/>explained_var =<br/>1 - Var(z-v) / Var(z)"]
    
    CALC_EXPL --> PRINT_STATS["æ‰“å°çµ±è¨ˆ:<br/>kl, lr_multiplier<br/>loss, entropy<br/>explained_var_old/new"]
    PRINT_STATS --> TRAIN_END["è¿”å› loss, entropy"]
    
    SKIP_TRAIN --> CHECK_EVAL
    TRAIN_END --> CHECK_EVAL{"(i+1) %<br/>check_freq<br/>== 0?"}
    
    CHECK_EVAL -->|å¦| NEXT_BATCH
    CHECK_EVAL -->|æ˜¯| EVAL["policy_evaluate()<br/>æ€§èƒ½è©•ä¼°"]
    
    EVAL --> EVAL_INIT["å‰µå»ºè©•ä¼°ç©å®¶<br/>current_mcts (is_selfplay=0)<br/>pure_mcts (ç´” MCTS)<br/>â”œâ”€ c_puct=5<br/>â””â”€ n_playout=è¨­å®šå€¼"]
    EVAL_INIT --> EVAL_GAMES["å°å±€ n_games å ´<br/>start_play()<br/>â”œâ”€ äº¤æ›¿å…ˆæ‰‹<br/>â””â”€ ç„¡é›œè¨Š (ç¢ºå®šæ€§)"]
    EVAL_GAMES --> CALC_WIN["è¨ˆç®—å‹ç‡<br/>win_ratio =<br/>(win + 0.5Ã—tie) / n_games"]
    CALC_WIN --> SAVE_CUR["ä¿å­˜ç•¶å‰æ¨¡å‹<br/>â†’ current_policy.model"]
    
    SAVE_CUR --> CHECK_BEST{"win_ratio ><br/>best_win_ratio?"}
    
    CHECK_BEST -->|æ˜¯| SAVE_BEST["ğŸ† æ–°æœ€ä½³æ¨¡å‹!<br/>best_win_ratio = win_ratio<br/>ä¿å­˜ â†’ best_policy.model"]
    CHECK_BEST -->|å¦| NOT_BEST["ä¿æŒèˆŠçš„ best_policy"]
    SAVE_BEST --> CHECK_PERFECT{"best_win_ratio<br/>== 1.0 AND<br/>playout < 5000?"}
    NOT_BEST --> NEXT_BATCH
    
    CHECK_PERFECT -->|æ˜¯| UP_DIFFICULTY["æå‡è©•ä¼°é›£åº¦<br/>pure_mcts_playout += 1000<br/>best_win_ratio = 0.0<br/>(é‡æ–°æŒ‘æˆ°)"]
    CHECK_PERFECT -->|å¦| NEXT_BATCH
    UP_DIFFICULTY --> NEXT_BATCH
    
    NEXT_BATCH{"i < game_batch_num<br/>- 1?"}
    
    NEXT_BATCH -->|æ˜¯| BATCH_LOOP
    NEXT_BATCH -->|å¦| SUCCESS["âœ“ è¨“ç·´å®Œæˆ<br/>best_policy.model"]
    SUCCESS --> NORMAL_END([æ­£å¸¸çµæŸ])
    
    BATCH_LOOP -.->|KeyboardInterrupt| INTERRUPT["æ•ç² Ctrl+C"]
    INTERRUPT --> QUIT["print('quit')"]
    QUIT --> QUIT_END([ä¸­æ–·çµæŸ])
    
    style START fill:#90EE90
    style NORMAL_END fill:#FFB6C6
    style QUIT_END fill:#FF6B6B
    style ERROR1 fill:#FF6B6B
    style EARLY_STOP fill:#FFE4B5
    style SAVE_BEST fill:#FFD700
    style UP_DIFFICULTY fill:#87CEEB
    style DIRICHLET fill:#FFB6C1
    style SINGLE_PLAYOUT fill:#E6E6FA
    style AUG_DETAIL fill:#E6E6FA
    style EVAL_GAMES fill:#E6E6FA
    style TRAIN_STEP fill:#F0E68C
```

## æµç¨‹åœ–è©³ç´°èªªæ˜

### ğŸ”´ ä¸»è¦éšæ®µ

####  **åˆå§‹åŒ–éšæ®µ** (START â†’ RUN)
```
â”œâ”€ è§£æå‘½ä»¤è¡Œåƒæ•¸
â”œâ”€ åŠ è¼‰ config.json
â”œâ”€ è¨­å®šæ£‹ç›¤åƒæ•¸
â”œâ”€ æª¢æŸ¥ GPU å¯ç”¨æ€§
â”œâ”€ åŠ è¼‰ç¥ç¶“ç¶²è·¯ (ResNet)
â””â”€ åˆå§‹åŒ– MCTS ç©å®¶
```

####  **è‡ªæˆ‘å°å¼ˆè³‡æ–™æ”¶é›†** (collect_selfplay_data)
```
play_batch_size å ´éŠæˆ²:
â”œâ”€ åˆå§‹åŒ–æ£‹ç›¤
â”œâ”€ å¾ªç’°åŸ·è¡Œè‘—æ³• (ç›´åˆ°éŠæˆ²çµæŸ):
â”‚  â”œâ”€ MCTS: n_playout æ¬¡æ¨¡æ“¬æœç´¢
â”‚  â”œâ”€ è‘—æ³•é¸æ“‡: temperature=temp
â”‚  â”œâ”€ è¨˜éŒ„: (state, mcts_prob)
â”‚  â””â”€ åŸ·è¡Œè‘—æ³•
â”œâ”€ è¿”å›: (winner, play_data)
â””â”€ å„²å­˜ episode_len
```

####  **è³‡æ–™å¢å¼·** (get_equi_data)
```
å°æ¯å±€æ£‹:
â”œâ”€ æ—‹è½‰ 4 æ¬¡ (0Â°, 90Â°, 180Â°, 270Â°)
â””â”€ å°æ¯å€‹æ—‹è½‰åšç¿»è½‰ (2 æ¬¡)
   â””â”€ ç”Ÿæˆ 8 å€ç­‰åƒ¹æ£‹å±€
```

####  **ç¶²è·¯è¨“ç·´** (policy_update)
```
if data_buffer.size > batch_size:
  â”œâ”€ éš¨æ©Ÿæ¡æ¨£ mini_batch
  â”œâ”€ è¨ˆç®—èˆŠç­–ç•¥ (old_probs, old_v)
  â”œâ”€ è¨“ç·´è¿´åœˆ (epochs æ¬¡):
  â”‚  â”œâ”€ å‰å‘å‚³æ’­
  â”‚  â”œâ”€ è¨ˆç®—æå¤±: L = L_policy + L_value
  â”‚  â”œâ”€ åå‘å‚³æ’­ + å„ªåŒ–
  â”‚  â”œâ”€ è¨ˆç®—æ–°ç­–ç•¥ (new_probs, new_v)
  â”‚  â”œâ”€ è¨ˆç®— KL æ•£åº¦
  â”‚  â””â”€ if KL > 4Ã—target: break (æå‰åœæ­¢)
  â”‚
  â”œâ”€ å‹•æ…‹å­¸ç¿’ç‡èª¿æ•´:
  â”‚  â”œâ”€ if KL > 2Ã—target: lr_multiplier /= 1.5 (é™é€Ÿ)
  â”‚  â””â”€ if KL < target/2: lr_multiplier Ã—= 1.5 (åŠ é€Ÿ)
  â”‚
  â””â”€ æ‰“å°çµ±è¨ˆä¿¡æ¯
```

####  **å®šæœŸè©•ä¼°** (policy_evaluate)
```
if (i+1) % check_freq == 0:
  â”œâ”€ åŸ·è¡Œ n_games å ´è©•ä¼°éŠæˆ²
  â”œâ”€ å°æ‰‹: Pure MCTS (N=pure_mcts_playout_num)
  â”œâ”€ è¨ˆç®—å‹ç‡
  â”œâ”€ ä¿å­˜ current_policy.model
  â”‚
  â””â”€ if win_ratio > best_win_ratio:
     â”œâ”€ ä¿å­˜ best_policy.model (æ–°æœ€ä½³)
     â””â”€ if win_ratio == 100%:
        â””â”€ æé«˜é›£åº¦: pure_mcts_playout_num += 1000
```

###  é—œéµè®Šæ•¸è¿½è¹¤

|            è®Šæ•¸             |                 ç”¨é€”              |
|-----------------------------|-----------------------------------|
| **data_buffer**             | å„²å­˜è‡ªæˆ‘å°å¼ˆè³‡æ–™ (æœ€å¤š buffer_size) |
| **lr_multiplier**           | å‹•æ…‹å­¸ç¿’ç‡å€æ•¸ (ç¯„åœ: 0.1~10)       |
| **best_win_ratio**          | è¿½è¹¤æœ€ä½³æ¨¡å‹æ€§èƒ½                    |
| **episode_len**             | æ¯å ´éŠæˆ²çš„æ­¥æ•¸                      |
| **pure_mcts_playout_num**   | è©•ä¼°é›£åº¦ (é€æ¼¸å¢åŠ )                 |

###  æ€§èƒ½æœ€ä½³åŒ–é»

1. **æ—©æœŸåœæ­¢ (Early Stopping)**
   ```python
   if kl > self.kl_targ * 4:
       break  # é¿å…éåº¦è¨“ç·´
   ```

2. **è‡ªé©æ‡‰å­¸ç¿’ç‡**
   ```python
   if kl > 2Ã—target:
       lr_multiplier /= 1.5  # å¤ªå¿«é™é€Ÿ
   elif kl < target/2:
       lr_multiplier *= 1.5  # å¤ªæ…¢åŠ é€Ÿ
   ```

3. **æ¼¸é€²å¼é›£åº¦æå‡**
   ```python
   if win_ratio == 1.0 and playout < 5000:
       pure_mcts_playout_num += 1000  # é‚ªæƒ¡é›£åº¦
   ```

###  æ±ºç­–é‚è¼¯

```
è¨“ç·´æµç¨‹æ±ºç­–æ¨¹:

START
  â†“
æ‰¹æ¬¡ i (0 to game_batch_num-1)
  â”œâ”€ æ”¶é›† play_batch_size å ´è‡ªæˆ‘å°å¼ˆ
  â”œâ”€ è³‡æ–™å¢å¼· (8Ã—æ“´å±•)
  â”œâ”€ buffer è¶³å¤ ? â†’ è¨“ç·´ç¶²è·¯
  â”‚  â””â”€ KL ç›£æ§ & å­¸ç¿’ç‡èª¿æ•´
  â”‚
  â””â”€ æ¯ check_freq æ‰¹:
     â”œâ”€ è©•ä¼° vs Pure MCTS
     â”œâ”€ è¶…è¶Šæœ€ä½³? â†’ ä¿å­˜æ–°æœ€ä½³
     â””â”€ 100% å‹ç‡? â†’ æé«˜ Pure MCTS é›£åº¦(self play MCTSæ¨¡æ“¬æ¬¡æ•¸ +1000)
       â””â”€ é‡ç½®è©•ä¼° (ç¹¼çºŒé€²æ­¥)
```

###  ä¸­æ–·è™•ç†

```
try:
  åŸ·è¡Œè¨“ç·´è¿´åœˆ
except KeyboardInterrupt:
  print('quit')  # (Ctrl+C)
```
